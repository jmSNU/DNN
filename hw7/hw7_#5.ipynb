{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Average Pixel Difference: 7.968885967768458e-17\n",
      "Files already downloaded and verified\n",
      "Average Pixel Diff: 1.87191713774579e-16\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 18 * 18, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "          nn.Conv2d(256, 4096, kernel_size=18),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(4096,4096,kernel_size=1),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(4096, num_classes,kernel_size=1)\n",
    "      )\n",
    "\n",
    "    def copy_weights_from(self, net1):\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(self.features), 2):\n",
    "                self.features[i].weight.copy_(net1.features[i].weight)\n",
    "                self.features[i].bias.copy_(net1.features[i].bias)\n",
    "\n",
    "            for i in range(len(self.classifier)):\n",
    "                if i == 1 or i == 3:\n",
    "                    continue\n",
    "                self.classifier[i].weight.copy_(net1.classifier[i].weight.view(self.classifier[i].weight.size()))\n",
    "                self.classifier[i].bias.copy_(net1.classifier[i].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model1 = Net1() # model1 randomly initialized\n",
    "model2 = Net2()\n",
    "model2.copy_weights_from(model1)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "imgs, _ = next(iter(test_loader))\n",
    "diff = torch.mean((model1(imgs) - model2(imgs).squeeze()) ** 2)\n",
    "print(f\"Average Pixel Difference: {diff.item()}\") # should be small\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((36, 38)),\n",
    "        torchvision.transforms.ToTensor()\n",
    "        ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "images, _ = next(iter(test_loader))\n",
    "b, w, h = images.shape[0], images.shape[-1], images.shape[-2]\n",
    "out1 = torch.empty((b, 10, h - 31, w - 31))\n",
    "for i in range(h - 31):\n",
    "    for j in range(w - 31):\n",
    "        out1[:, :, i, j] = model1(images[:, :, i:i+32, j:j+32])\n",
    "out2 = model2(images)\n",
    "diff = torch.mean((out1 - out2) ** 2)\n",
    "\n",
    "print(f\"Average Pixel Diff: {diff.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
