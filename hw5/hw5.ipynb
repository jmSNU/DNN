{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 : Implementation\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3943e-05, 3.7064e-05, 4.2687e-06, 6.3700e-06],\n",
      "        [3.4104e-05, 5.2794e-05, 6.0804e-06, 9.0735e-06],\n",
      "        [2.4438e-05, 3.7831e-05, 4.3571e-06, 6.5019e-06],\n",
      "        [2.0187e-05, 3.1250e-05, 3.5991e-06, 5.3707e-06]])\n",
      "tensor([4.8247e-05, 6.8722e-05, 4.9245e-05, 4.0678e-05])\n",
      "\n",
      "tensor([[2.3943e-05, 3.7064e-05, 4.2687e-06, 6.3700e-06],\n",
      "        [3.4104e-05, 5.2794e-05, 6.0804e-06, 9.0735e-06],\n",
      "        [2.4438e-05, 3.7831e-05, 4.3571e-06, 6.5019e-06],\n",
      "        [2.0187e-05, 3.1250e-05, 3.5991e-06, 5.3707e-06]])\n",
      "tensor([[4.8247e-05, 6.8722e-05, 4.9245e-05, 4.0678e-05]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def sigma(x):\n",
    "    return torch.sigmoid(x)\n",
    "def sigma_prime(x):\n",
    "    return sigma(x)*(1-sigma(x))\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "L = 6\n",
    "X_data = torch.rand(4, 1)\n",
    "Y_data = torch.rand(1, 1)\n",
    "\n",
    "A_list,b_list = [],[]\n",
    "for _ in range(L-1):\n",
    "    A_list.append(torch.rand(4, 4))\n",
    "    b_list.append(torch.rand(4, 1))\n",
    "A_list.append(torch.rand(1, 4))\n",
    "b_list.append(torch.rand(1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# # Option 1: directly use PyTorch's autograd feature\n",
    "# for A in A_list:\n",
    "#     A.requires_grad = True\n",
    "# for b in b_list:\n",
    "#     b.requires_grad = True\n",
    "    \n",
    "# y = X_data\n",
    "# for ell in range(L):\n",
    "#     S = sigma if ell<L-1 else lambda x: x\n",
    "#     y = S(A_list[ell]@y+b_list[ell])\n",
    "    \n",
    "# # backward pass in pytorch\n",
    "# loss=torch.square(y-Y_data)/2\n",
    "# loss.backward()\n",
    "\n",
    "# print(A_list[0].grad)\n",
    "\n",
    "\n",
    "# Option 2: construct a NN model and use backprop\n",
    "class MLP(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.ModuleList([nn.Linear(4,4) for _ in range(L-1)])\n",
    "        self.linear.append(nn.Linear(4,1))\n",
    "        for ell in range(L):\n",
    "            self.linear[ell].weight.data = A_list[ell]\n",
    "            self.linear[ell].bias.data = b_list[ell].squeeze()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = x.squeeze()\n",
    "        for ell in range(L-1):\n",
    "            x = sigma(self.linear[ell](x))\n",
    "        x = self.linear[-1](x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "            \n",
    "loss = torch.square(model(X_data)-Y_data)/2\n",
    "loss.backward()\n",
    "\n",
    "print(model.linear[0].weight.grad)\n",
    "print(model.linear[0].bias.grad)\n",
    "print()\n",
    "\n",
    "# Option 3: implement backprop yourself\n",
    "y_list = [X_data]\n",
    "y = X_data\n",
    "for ell in range(L):\n",
    "    S = sigma if ell<L-1 else lambda x: x\n",
    "    y = S(A_list[ell]@y+b_list[ell])\n",
    "    y_list.append(y)\n",
    "\n",
    "\n",
    "dA_list = []\n",
    "db_list = []\n",
    "dy = y-Y_data  # dloss/dy_L\n",
    "for ell in reversed(range(L)):\n",
    "    S = sigma_prime if ell<L-1 else lambda x: torch.ones(x.shape)\n",
    "    A, b, y = A_list[ell], b_list[ell], y_list[ell] # A = A_l, b = b_l, y_l\n",
    "\n",
    "    db = torch.mm(dy,torch.diag(S(A@y + b).flatten()))   # dloss/db_ell\n",
    "    dA = torch.mm(y, db).T   # dloss/dA_ell\n",
    "    dy = torch.mm(db, A)     # dloss/dy_{ell-1}\n",
    "    \n",
    "\n",
    "    dA_list.insert(0, dA)\n",
    "    db_list.insert(0, db)\n",
    "\n",
    "print(dA_list[0])\n",
    "print(db_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230943744"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*256*25-1)*96*32*32 +(2*256*9-1)*(192*32*32) + (2*256*1-1)*(128*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346720"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*256*128+128 + 1*256*64+64 + 9*64*192+192 + 1*256*64+64 + 25*64*96+96 + 1*256*64+64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368574464"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*256*1-1)*(128*32*32) + (2*256*1-1)*64*32*32*2 + (2*64*9-1)*(192*32*32) + (2*64*1-1)*(64*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [filter size, stride, padding]\n",
    "#Assume the two dimensions are the same\n",
    "#Each kernel requires the following parameters:\n",
    "# - k_i: kernel size\n",
    "# - s_i: stride\n",
    "# - p_i: padding (if padding is uneven, right padding will higher than left padding; \"SAME\" option in tensorflow)\n",
    "# \n",
    "#Each layer i requires the following parameters to be fully represented: \n",
    "# - n_i: number of feature (data layer has n_1 = imagesize )\n",
    "# - j_i: distance (projected to image pixel distance) between center of two adjacent features\n",
    "# - r_i: receptive field of a feature in layer i\n",
    "# - start_i: position of the first feature's receptive field in layer i (idx start from 0, negative means the center fall into padding)\n",
    "\n",
    "import math\n",
    "convnet =   [[3,1,1],[3,1,1],[2,2,0],[3,1,1],[3,1,1],[2,2,0]]\n",
    "layer_names = ['conv1','conv2','pool1','conv3','conv4','pool2']\n",
    "imsize = 224\n",
    "\n",
    "def outFromIn(conv, layerIn):\n",
    "  n_in = layerIn[0]\n",
    "  j_in = layerIn[1]\n",
    "  r_in = layerIn[2]\n",
    "  start_in = layerIn[3]\n",
    "  k = conv[0]\n",
    "  s = conv[1]\n",
    "  p = conv[2]\n",
    "  \n",
    "  n_out = math.floor((n_in - k + 2*p)/s) + 1\n",
    "  actualP = (n_out-1)*s - n_in + k \n",
    "  pR = math.ceil(actualP/2)\n",
    "  pL = math.floor(actualP/2)\n",
    "  \n",
    "  j_out = j_in * s\n",
    "  r_out = r_in + (k - 1)*j_in\n",
    "  start_out = start_in + ((k-1)/2 - pL)*j_in\n",
    "  return n_out, j_out, r_out, start_out\n",
    "  \n",
    "def printLayer(layer, layer_name):\n",
    "  print(layer_name + \":\")\n",
    "  print(\"\\t n features: %s \\n \\t jump: %s \\n \\t receptive size: %s \\t start: %s \" % (layer[0], layer[1], layer[2], layer[3]))\n",
    " \n",
    "layerInfos = []\n",
    "if __name__ == '__main__':\n",
    "#first layer is the data layer (image) with n_0 = image size; j_0 = 1; r_0 = 1; and start_0 = 0.5\n",
    "  print (\"-------Net summary------\")\n",
    "  currentLayer = [imsize, 1, 1, 0.5]\n",
    "  printLayer(currentLayer, \"input image\")\n",
    "  for i in range(len(convnet)):\n",
    "    currentLayer = outFromIn(convnet[i], currentLayer)\n",
    "    layerInfos.append(currentLayer)\n",
    "    printLayer(currentLayer, layer_names[i])\n",
    "  print (\"------------------------\")\n",
    "  layer_name = input(\"Layer name where the feature in: \")\n",
    "  layer_idx = layer_names.index(layer_name)\n",
    "  idx_x = int(input(\"index of the feature in x dimension (from 0)\"))\n",
    "  idx_y = int(input(\"index of the feature in y dimension (from 0)\"))\n",
    "  \n",
    "  n = layerInfos[layer_idx][0]\n",
    "  j = layerInfos[layer_idx][1]\n",
    "  r = layerInfos[layer_idx][2]\n",
    "  start = layerInfos[layer_idx][3]\n",
    "  assert(idx_x < n)\n",
    "  assert(idx_y < n)\n",
    "  \n",
    "  print (\"receptive field: (%s, %s)\" % (r, r))\n",
    "  print (\"center: (%s, %s)\" % (start+idx_x*j, start+idx_y*j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6 : Implementation\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3623851.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2644884.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1722249.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "\n",
      "Experiment with 0% randomized labels\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 130\u001b[0m\n\u001b[0;32m    128\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(model(images), labels)\n\u001b[0;32m    129\u001b[0m     tmp2_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m--> 130\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    132\u001b[0m tmp_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(tmp2_losses))\n",
      "File \u001b[1;32mc:\\Users\\JM\\anaconda3\\envs\\py3_11\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JM\\anaconda3\\envs\\py3_11\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Make sure to use only 10% of the available MNIST data.\n",
    "# Otherwise, experiment will take quite long (around 90 minutes).\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "learning_rate = 0.1\n",
    "batch_size = 64\n",
    "epochs = 150\n",
    "\n",
    "def create_randomized_dataset(train_data, label_ratio):\n",
    "    subset_indices = np.random.choice(len(train_data), len(train_data), replace=False)\n",
    "    num_random_labels = int(len(train_data) * label_ratio)\n",
    "    random_labels = torch.randint(low=0, high=10, size=(num_random_labels,))\n",
    "    labels = torch.cat((train_data.targets[:num_random_labels], random_labels), dim=0)\n",
    "    subset = torch.utils.data.Subset(train_data, subset_indices)\n",
    "    subset.targets = labels\n",
    "    return subset\n",
    "\n",
    "# Evaluate the accuracy of the model on the test dataset\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total * 100\n",
    "    return accuracy\n",
    "\n",
    "# (Modified version of AlexNet)\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_class=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(6400, 800),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(800, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv_layer1(x)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.conv_layer3(output)\n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.fc_layer1(output)\n",
    "        return output\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_data = datasets.MNIST(root='./', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define the ratios of randomized labels to experiment with\n",
    "label_ratios = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "test_data = datasets.MNIST(root='./', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define a data loader for the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AlexNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "losses = []\n",
    "times = []\n",
    "acc = []\n",
    "\n",
    "for label_ratio in label_ratios:\n",
    "    print(f\"\\nExperiment with {int(label_ratio * 100)}% randomized labels\")\n",
    "    tmp_losses = []\n",
    "\n",
    "    # Create a dataset subset with the specified label ratio\n",
    "    train_subset = create_randomized_dataset(train_data, label_ratio)\n",
    "\n",
    "    # Define a data loader for the subset\n",
    "    batch_size = 64\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the model, optimizer, and loss function\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AlexNet().to(device)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    tick = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        tmp2_losses = []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(model(images), labels)\n",
    "            tmp2_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        tmp_losses.append(np.mean(tmp2_losses))\n",
    "    tock = time.time()\n",
    "    accuracy = test_model(model, test_loader)\n",
    "    \n",
    "    # logging\n",
    "    losses.append(tmp_losses)\n",
    "    times.append(tock-tick)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "    print(f\"Total training time: {tock - tick}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
