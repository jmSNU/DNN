{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 : Implementation\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3943e-05, 3.7064e-05, 4.2687e-06, 6.3700e-06],\n",
      "        [3.4104e-05, 5.2794e-05, 6.0804e-06, 9.0735e-06],\n",
      "        [2.4438e-05, 3.7831e-05, 4.3571e-06, 6.5019e-06],\n",
      "        [2.0187e-05, 3.1250e-05, 3.5991e-06, 5.3707e-06]])\n",
      "tensor([4.8247e-05, 6.8722e-05, 4.9245e-05, 4.0678e-05])\n",
      "\n",
      "tensor([[2.3943e-05, 3.7064e-05, 4.2687e-06, 6.3700e-06],\n",
      "        [3.4104e-05, 5.2794e-05, 6.0804e-06, 9.0735e-06],\n",
      "        [2.4438e-05, 3.7831e-05, 4.3571e-06, 6.5019e-06],\n",
      "        [2.0187e-05, 3.1250e-05, 3.5991e-06, 5.3707e-06]])\n",
      "tensor([[4.8247e-05, 6.8722e-05, 4.9245e-05, 4.0678e-05]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def sigma(x):\n",
    "    return torch.sigmoid(x)\n",
    "def sigma_prime(x):\n",
    "    return sigma(x)*(1-sigma(x))\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "L = 6\n",
    "X_data = torch.rand(4, 1)\n",
    "Y_data = torch.rand(1, 1)\n",
    "\n",
    "A_list,b_list = [],[]\n",
    "for _ in range(L-1):\n",
    "    A_list.append(torch.rand(4, 4))\n",
    "    b_list.append(torch.rand(4, 1))\n",
    "A_list.append(torch.rand(1, 4))\n",
    "b_list.append(torch.rand(1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# # Option 1: directly use PyTorch's autograd feature\n",
    "# for A in A_list:\n",
    "#     A.requires_grad = True\n",
    "# for b in b_list:\n",
    "#     b.requires_grad = True\n",
    "    \n",
    "# y = X_data\n",
    "# for ell in range(L):\n",
    "#     S = sigma if ell<L-1 else lambda x: x\n",
    "#     y = S(A_list[ell]@y+b_list[ell])\n",
    "    \n",
    "# # backward pass in pytorch\n",
    "# loss=torch.square(y-Y_data)/2\n",
    "# loss.backward()\n",
    "\n",
    "# print(A_list[0].grad)\n",
    "\n",
    "\n",
    "# Option 2: construct a NN model and use backprop\n",
    "class MLP(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.ModuleList([nn.Linear(4,4) for _ in range(L-1)])\n",
    "        self.linear.append(nn.Linear(4,1))\n",
    "        for ell in range(L):\n",
    "            self.linear[ell].weight.data = A_list[ell]\n",
    "            self.linear[ell].bias.data = b_list[ell].squeeze()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = x.squeeze()\n",
    "        for ell in range(L-1):\n",
    "            x = sigma(self.linear[ell](x))\n",
    "        x = self.linear[-1](x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "            \n",
    "loss = torch.square(model(X_data)-Y_data)/2\n",
    "loss.backward()\n",
    "\n",
    "print(model.linear[0].weight.grad)\n",
    "print(model.linear[0].bias.grad)\n",
    "print()\n",
    "\n",
    "# Option 3: implement backprop yourself\n",
    "y_list = [X_data]\n",
    "y = X_data\n",
    "for ell in range(L):\n",
    "    S = sigma if ell<L-1 else lambda x: x\n",
    "    y = S(A_list[ell]@y+b_list[ell])\n",
    "    y_list.append(y)\n",
    "\n",
    "\n",
    "dA_list = []\n",
    "db_list = []\n",
    "dy = y-Y_data  # dloss/dy_L\n",
    "for ell in reversed(range(L)):\n",
    "    S = sigma_prime if ell<L-1 else lambda x: torch.ones(x.shape)\n",
    "    A, b, y = A_list[ell], b_list[ell], y_list[ell] # A = A_l, b = b_l, y_l\n",
    "\n",
    "    db = torch.mm(dy,torch.diag(S(A@y + b).flatten()))   # dloss/db_ell\n",
    "    dA = torch.mm(y, db).T   # dloss/dA_ell\n",
    "    dy = torch.mm(db, A)     # dloss/dy_{ell-1}\n",
    "    \n",
    "\n",
    "    dA_list.insert(0, dA)\n",
    "    db_list.insert(0, db)\n",
    "\n",
    "print(dA_list[0])\n",
    "print(db_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230943744"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*256*25-1)*96*32*32 +(2*256*9-1)*(192*32*32) + (2*256*1-1)*(128*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346720"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*256*128+128 + 1*256*64+64 + 9*64*192+192 + 1*256*64+64 + 25*64*96+96 + 1*256*64+64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368574464"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*256*1-1)*(128*32*32) + (2*256*1-1)*64*32*32*2 + (2*64*9-1)*(192*32*32) + (2*64*1-1)*(64*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [filter size, stride, padding]\n",
    "#Assume the two dimensions are the same\n",
    "#Each kernel requires the following parameters:\n",
    "# - k_i: kernel size\n",
    "# - s_i: stride\n",
    "# - p_i: padding (if padding is uneven, right padding will higher than left padding; \"SAME\" option in tensorflow)\n",
    "# \n",
    "#Each layer i requires the following parameters to be fully represented: \n",
    "# - n_i: number of feature (data layer has n_1 = imagesize )\n",
    "# - j_i: distance (projected to image pixel distance) between center of two adjacent features\n",
    "# - r_i: receptive field of a feature in layer i\n",
    "# - start_i: position of the first feature's receptive field in layer i (idx start from 0, negative means the center fall into padding)\n",
    "\n",
    "import math\n",
    "convnet =   [[3,1,1],[3,1,1],[2,2,0],[3,1,1],[3,1,1],[2,2,0]]\n",
    "layer_names = ['conv1','conv2','pool1','conv3','conv4','pool2']\n",
    "imsize = 224\n",
    "\n",
    "def outFromIn(conv, layerIn):\n",
    "  n_in = layerIn[0]\n",
    "  j_in = layerIn[1]\n",
    "  r_in = layerIn[2]\n",
    "  start_in = layerIn[3]\n",
    "  k = conv[0]\n",
    "  s = conv[1]\n",
    "  p = conv[2]\n",
    "  \n",
    "  n_out = math.floor((n_in - k + 2*p)/s) + 1\n",
    "  actualP = (n_out-1)*s - n_in + k \n",
    "  pR = math.ceil(actualP/2)\n",
    "  pL = math.floor(actualP/2)\n",
    "  \n",
    "  j_out = j_in * s\n",
    "  r_out = r_in + (k - 1)*j_in\n",
    "  start_out = start_in + ((k-1)/2 - pL)*j_in\n",
    "  return n_out, j_out, r_out, start_out\n",
    "  \n",
    "def printLayer(layer, layer_name):\n",
    "  print(layer_name + \":\")\n",
    "  print(\"\\t n features: %s \\n \\t jump: %s \\n \\t receptive size: %s \\t start: %s \" % (layer[0], layer[1], layer[2], layer[3]))\n",
    " \n",
    "layerInfos = []\n",
    "if __name__ == '__main__':\n",
    "#first layer is the data layer (image) with n_0 = image size; j_0 = 1; r_0 = 1; and start_0 = 0.5\n",
    "  print (\"-------Net summary------\")\n",
    "  currentLayer = [imsize, 1, 1, 0.5]\n",
    "  printLayer(currentLayer, \"input image\")\n",
    "  for i in range(len(convnet)):\n",
    "    currentLayer = outFromIn(convnet[i], currentLayer)\n",
    "    layerInfos.append(currentLayer)\n",
    "    printLayer(currentLayer, layer_names[i])\n",
    "  print (\"------------------------\")\n",
    "  layer_name = input(\"Layer name where the feature in: \")\n",
    "  layer_idx = layer_names.index(layer_name)\n",
    "  idx_x = int(input(\"index of the feature in x dimension (from 0)\"))\n",
    "  idx_y = int(input(\"index of the feature in y dimension (from 0)\"))\n",
    "  \n",
    "  n = layerInfos[layer_idx][0]\n",
    "  j = layerInfos[layer_idx][1]\n",
    "  r = layerInfos[layer_idx][2]\n",
    "  start = layerInfos[layer_idx][3]\n",
    "  assert(idx_x < n)\n",
    "  assert(idx_y < n)\n",
    "  \n",
    "  print (\"receptive field: (%s, %s)\" % (r, r))\n",
    "  print (\"center: (%s, %s)\" % (start+idx_x*j, start+idx_y*j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6 : Implementation\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Make sure to use only 10% of the available MNIST data.\n",
    "# Otherwise, experiment will take quite long (around 90 minutes).\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_randomized_dataset(train_data, label_ratio):\n",
    "    subset_indices = np.random.choice(len(train_data), len(train_data), replace=False)\n",
    "    num_random_labels = int(len(train_data) * label_ratio)\n",
    "    random_labels = torch.randint(low=0, high=10, size=(num_random_labels,))\n",
    "    labels = torch.cat((train_data.targets[:num_random_labels], random_labels), dim=0)\n",
    "    subset = torch.utils.data.Subset(train_data, subset_indices)\n",
    "    subset.targets = labels\n",
    "    return subset\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_data = datasets.MNIST(root='./', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define the ratios of randomized labels to experiment with\n",
    "label_ratios = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "\n",
    "# (Modified version of AlexNet)\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_class=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(6400, 800),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(800, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv_layer1(x)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.conv_layer3(output)\n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.fc_layer1(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "batch_size = 64\n",
    "epochs = 150\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AlexNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "tick = time.time()\n",
    "for epoch in range(150):\n",
    "    print(f\"\\nEpoch {epoch + 1} / {epochs}\")\n",
    "    for images, labels in train_loader:\n",
    "        # images, labels = images.to(device), labels.to(device)\n",
    "        images, labels = images.to(device), random_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model(images), labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "tock = time.time()\n",
    "print(f\"Total training time: {tock - tick}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
